{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\"\"\"By Aryan Deorah\nPredicts Survival on Titanic\"\"\"\n\n#imports pandas as pd\nimport pandas as pd\n\n#imports the training and test data sets as data and test respectively\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n#prints the train columns, info regarding the train and test dataset, a description of the train data, and a few rows of data\nprint (train.columns)\nprint('_'*40)\nprint (train.info())\nprint('_'*40)\nprint (test.info())\nprint('_'*40)\nprint (train.describe())\nprint('_'*40)\nprint (train.head())\nprint('_'*40)\n\n#prints the rate of survival for the unique inputs of the Pclass, SibSp, Sex, Parch, and Embarked\n#Class, Sex, and Embarked seem to have correlation, while SibSp and Parch do not\nprint (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))\nprint('_'*40)\nprint (train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))\nprint('_'*40)\nprint (train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))\nprint('_'*40)\nprint (train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))\nprint('_'*40)\nprint (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False))\nprint('_'*40)\n\n#prints the head of the data for the Ticket and Name columns, demonstrating why they should not be used\nprint (train.Ticket.head())\nprint('_'*40)\nprint (train.Name.head())\nprint('_'*40)\n\n#drops the ticket and cabin columns due to missing inputs and no percived usefullness, passengerId is dropped from train set, creates combine, which had train and test in it\ntrain=train.drop(['PassengerId','Ticket','Cabin'], axis=1)\ntest=test.drop(['Ticket','Cabin'], axis=1)\ncombine=[train,test]\n\n#loops through datasets in combine and sets age values in different ranges equal to a specific number\nfor dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 5, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 5) & (dataset['Age'] <= 18), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 35), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 35) & (dataset['Age'] <= 65), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 65, 'Age']=4\n\n#prints the rate of survival for the unique inputs of Age, showing a sort of negative correlation\nprint (train[['Age', 'Survived']].groupby(['Age'], as_index=False).mean().sort_values(by='Survived', ascending=False))\nprint('_'*40)\n\n#loops through datasets in combine and creates a new column IsAlone with a 1 if the passenger was alone and 0 if they were not\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['SibSp'] + dataset['Parch'] == 0, 'IsAlone'] = 1\n\n#prints the rate of survival for the unique inputs of IsAlone, showing a lower rate of survival for passengers traveling alone\nprint (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\nprint('_'*40)\n\n#drops Parch, SibSp, and Name for reasons mentioned above and sets combine equal to train and test again\ntrain=train.drop(['Parch','SibSp','Name'], axis=1)\ntest=test.drop(['Parch','SibSp','Name'], axis=1)\ncombine=[train,test]\n\n#sets freq_port equal to the port where the most passengers embarked replaces missing values with freq_port\nfreq_port = train.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n\n#replaces the port Initials with integers\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n#prints the quartile ranges for the Fare columns\nprint (pd.qcut(train['Fare'], 4))\nprint('_'*40)\n\n#fills missing Fare values with the median fare and replaces ranges of Fare values with integers according to the quartile ranges\nfor dataset in combine:\n    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].dropna().median())\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\n#prints the rate of survival for the unique inputs of Fare, showing a positive correlation\nprint (train[['Fare', 'Survived']].groupby(['Fare'], as_index=False).mean().sort_values(by='Survived', ascending=False))\nprint('_'*40)\n\n#replaces male and female with integers 1 and 0\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\n#prints the head of the train dataset\nprint (train.head())\nprint('_'*40)\n\n#sets y equal to the Survived values, X equal to the train dataset with the survived value dropped, and test_X equal to test with PassengerId dropped and prints the test columns\ny=train.Survived\nX=train.drop(\"Survived\", axis=1)\ntest_X=test.drop('PassengerId',axis=1)\nprint (test.columns)\n#imports make_pipeline, Imputer, and SimpleImputer, cross_val_score, and 9 different models\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n#creates evaluation, an empty list, and defines the evaluate function that takes one argument model\nevaluation=[]\ndef evaluate(model):\n    \n    #sets my_pipeline equal to SimpleImputer and the model, fits it to X and y, does predictions on test_X, and does cross validation scores\n    my_pipeline=make_pipeline(SimpleImputer(),model)\n    my_pipeline.fit(X, y)\n    predictions = my_pipeline.predict(test_X)\n    scores = cross_val_score(my_pipeline, X, y, scoring='neg_mean_absolute_error',cv=5)\n    \n    #prints the model, the cross validation scores, the mean of those scores and appends that to the evaluation list\n    print ('_'*40)\n    print (model)\n    print(scores)\n    print (scores.mean())\n    evaluation.append(scores.mean())\n\n#runs the evaluate function on all 9 models\nevaluate(LogisticRegression())\nevaluate(SVC())\nevaluate(LinearSVC())\nevaluate(RandomForestClassifier())\nevaluate(KNeighborsClassifier())\nevaluate(GaussianNB())\nevaluate(Perceptron())\nevaluate(SGDClassifier())\nevaluate(DecisionTreeClassifier())\n\n#prints the evaluation list, which shows the best cross validation score is with the SVC model\nprint ('_'*40)\nprint (evaluation)\n\n#sets my_pipeline equal to SimpleImputer and SVC, fits it to X and y, and does predictions on test_X\nmy_pipeline=make_pipeline(SimpleImputer(),SVC())\nmy_pipeline.fit(X, y)\npredictions = my_pipeline.predict(test_X)\n\n#sets the file my_submission to a table with two columns, PassengerId and Survived, which is the predictions and makes it a csv file\nmy_submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\nmy_submission.to_csv('submission.csv', index=False)\n",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train.csv', 'gender_submission.csv', 'test.csv']\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n________________________________________\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.6+ KB\nNone\n________________________________________\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\nPassengerId    418 non-null int64\nPclass         418 non-null int64\nName           418 non-null object\nSex            418 non-null object\nAge            332 non-null float64\nSibSp          418 non-null int64\nParch          418 non-null int64\nTicket         418 non-null object\nFare           417 non-null float64\nCabin          91 non-null object\nEmbarked       418 non-null object\ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\nNone\n________________________________________\n       PassengerId    Survived     ...           Parch        Fare\ncount   891.000000  891.000000     ...      891.000000  891.000000\nmean    446.000000    0.383838     ...        0.381594   32.204208\nstd     257.353842    0.486592     ...        0.806057   49.693429\nmin       1.000000    0.000000     ...        0.000000    0.000000\n25%     223.500000    0.000000     ...        0.000000    7.910400\n50%     446.000000    0.000000     ...        0.000000   14.454200\n75%     668.500000    1.000000     ...        0.000000   31.000000\nmax     891.000000    1.000000     ...        6.000000  512.329200\n\n[8 rows x 7 columns]\n________________________________________\n   PassengerId  Survived  Pclass    ...        Fare Cabin  Embarked\n0            1         0       3    ...      7.2500   NaN         S\n1            2         1       1    ...     71.2833   C85         C\n2            3         1       3    ...      7.9250   NaN         S\n3            4         1       1    ...     53.1000  C123         S\n4            5         0       3    ...      8.0500   NaN         S\n\n[5 rows x 12 columns]\n________________________________________\n   Pclass  Survived\n0       1  0.629630\n1       2  0.472826\n2       3  0.242363\n________________________________________\n   SibSp  Survived\n1      1  0.535885\n2      2  0.464286\n0      0  0.345395\n3      3  0.250000\n4      4  0.166667\n5      5  0.000000\n6      8  0.000000\n________________________________________\n      Sex  Survived\n0  female  0.742038\n1    male  0.188908\n________________________________________\n   Parch  Survived\n3      3  0.600000\n1      1  0.550847\n2      2  0.500000\n0      0  0.343658\n5      5  0.200000\n4      4  0.000000\n6      6  0.000000\n________________________________________\n  Embarked  Survived\n0        C  0.553571\n1        Q  0.389610\n2        S  0.336957\n________________________________________\n0           A/5 21171\n1            PC 17599\n2    STON/O2. 3101282\n3              113803\n4              373450\nName: Ticket, dtype: object\n________________________________________\n0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\nName: Name, dtype: object\n________________________________________\n   Age  Survived\n0  0.0  0.704545\n1  1.0  0.410526\n3  3.0  0.392344\n2  2.0  0.382682\n4  4.0  0.125000\n________________________________________\n   IsAlone  Survived\n0        0  0.505650\n1        1  0.303538\n________________________________________\n0       (-0.001, 7.91]\n1      (31.0, 512.329]\n2       (7.91, 14.454]\n3      (31.0, 512.329]\n4       (7.91, 14.454]\n5       (7.91, 14.454]\n6      (31.0, 512.329]\n7       (14.454, 31.0]\n8       (7.91, 14.454]\n9       (14.454, 31.0]\n10      (14.454, 31.0]\n11      (14.454, 31.0]\n12      (7.91, 14.454]\n13     (31.0, 512.329]\n14      (-0.001, 7.91]\n15      (14.454, 31.0]\n16      (14.454, 31.0]\n17      (7.91, 14.454]\n18      (14.454, 31.0]\n19      (-0.001, 7.91]\n20      (14.454, 31.0]\n21      (7.91, 14.454]\n22      (7.91, 14.454]\n23     (31.0, 512.329]\n24      (14.454, 31.0]\n25     (31.0, 512.329]\n26      (-0.001, 7.91]\n27     (31.0, 512.329]\n28      (-0.001, 7.91]\n29      (-0.001, 7.91]\n            ...       \n861     (7.91, 14.454]\n862     (14.454, 31.0]\n863    (31.0, 512.329]\n864     (7.91, 14.454]\n865     (7.91, 14.454]\n866     (7.91, 14.454]\n867    (31.0, 512.329]\n868     (7.91, 14.454]\n869     (7.91, 14.454]\n870     (-0.001, 7.91]\n871    (31.0, 512.329]\n872     (-0.001, 7.91]\n873     (7.91, 14.454]\n874     (14.454, 31.0]\n875     (-0.001, 7.91]\n876     (7.91, 14.454]\n877     (-0.001, 7.91]\n878     (-0.001, 7.91]\n879    (31.0, 512.329]\n880     (14.454, 31.0]\n881     (-0.001, 7.91]\n882     (7.91, 14.454]\n883     (7.91, 14.454]\n884     (-0.001, 7.91]\n885     (14.454, 31.0]\n886     (7.91, 14.454]\n887     (14.454, 31.0]\n888     (14.454, 31.0]\n889     (14.454, 31.0]\n890     (-0.001, 7.91]\nName: Fare, Length: 891, dtype: category\nCategories (4, interval[float64]): [(-0.001, 7.91] < (7.91, 14.454] < (14.454, 31.0] < (31.0, 512.329]]\n________________________________________\n   Fare  Survived\n3     3  0.581081\n2     2  0.445415\n1     1  0.308756\n0     0  0.197309\n________________________________________\n   Survived  Pclass  Sex  Age  Fare  Embarked  IsAlone\n0         0       3    0  2.0     0         0        0\n1         1       1    1  3.0     3         1        0\n2         1       3    1  2.0     1         0        1\n3         1       1    1  2.0     3         0        0\n4         0       3    0  2.0     1         0        1\n________________________________________\nIndex(['PassengerId', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'IsAlone'], dtype='object')\n________________________________________\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n[-0.22346369 -0.17877095 -0.21348315 -0.23033708 -0.19774011]\n-0.20875899491699196\n________________________________________\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False)\n[-0.16201117 -0.18994413 -0.19101124 -0.20786517 -0.16384181]\n-0.18293470393331127\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "________________________________________\nLinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0)\n[-0.20111732 -0.17877095 -0.21348315 -0.23033708 -0.20903955]\n-0.20654960817962492\n________________________________________\nRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\n[-0.22346369 -0.19553073 -0.15730337 -0.21910112 -0.17514124]\n-0.19410803014553935\n________________________________________\nKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')\n[-0.24581006 -0.22346369 -0.17977528 -0.17977528 -0.15819209]\n-0.19740327904199856\n________________________________________\nGaussianNB(priors=None, var_smoothing=1e-09)\n[-0.32402235 -0.18435754 -0.2247191  -0.23595506 -0.20903955]\n-0.23561871871882523\n________________________________________\nPerceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n      n_jobs=1, penalty=None, random_state=0, shuffle=True, tol=None,\n      validation_fraction=0.1, verbose=0, warm_start=False)\n[-0.44134078 -0.59776536 -0.19662921 -0.24719101 -0.24293785]\n-0.34517284461556846\n________________________________________\nSGDClassifier(alpha=0.0001, average=False, class_weight=None,\n       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n       n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='l2',\n       power_t=0.5, random_state=None, shuffle=True, tol=None,\n       validation_fraction=0.1, verbose=0, warm_start=False)\n[-0.2122905  -0.2122905  -0.19662921 -0.3258427  -0.18079096]\n-0.22556877523018581\n________________________________________\nDecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')\n[-0.23463687 -0.2122905  -0.17977528 -0.19101124 -0.16384181]\n-0.1963111398130426\n________________________________________\n[-0.20875899491699196, -0.18293470393331127, -0.20654960817962492, -0.19410803014553935, -0.19740327904199856, -0.23561871871882523, -0.34517284461556846, -0.22556877523018581, -0.1963111398130426]\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "246fabfdb8b4ea782b004a077e0b98ee6aab852e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}