{
  "cells": [
    {
      "metadata": {
        "_uuid": "b6269c0e8f417f82daf093dda8fa0da6d2c57d86",
        "_cell_guid": "e81ee64d-e474-4662-9036-ce23df615199"
      },
      "cell_type": "markdown",
      "source": "# Introduction\n**This will be your workspace for the [Machine Learning course](https://www.kaggle.com/learn/machine-learning).**\n\nYou will need to translate the concepts to work with the data in this notebook, the Iowa data. Each page in the Machine Learning course includes instructions for what code to write at that step in the course.\n\n# Write Your Code Below"
    },
    {
      "metadata": {
        "_uuid": "1c728098629e1301643443b1341556a15c089b2b",
        "_cell_guid": "86b26423-563a-4fa1-a595-89e25ff93089",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#imports pandas\nimport pandas as pd\n\n#sets variable equal to data adn makes it readable\nmain_file_path = '../input/house-prices-advanced-regression-techniques/train.csv' # this is the path to the Iowa data that you will use\ndata = pd.read_csv(main_file_path)\n\n#Prints the statistical description of the data and the collumn headers of teh data\nprint(data.describe())\nprint(data.columns)\n\n#sets variable sale_price equal to the sales price and prints out the first few rows of sales prices\nsale_price=data.SalePrice\nprint(sale_price.head())\n\n#sets coolcol equal to 2 column headers, sets coolcol_data equal to the corresponding data, and prints the description of coolcol_data\ncoolcol=['LotShape','LotConfig']\ncoolcol_data=data[coolcol]\nprint (coolcol_data.describe())\n\n#sets y equal to the prediction target, the sale price, and sets data_predictors equal to various column headers, and sets X equal to the corresponding data\ny=sale_price\ndata_predictors=['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd']\nX=data[data_predictors]\n\n#imports Decision Tree Regressor and defines cool_model as that, it fits cool model to X and y and print predictions from the model\nfrom sklearn.tree import DecisionTreeRegressor\ncool_model = DecisionTreeRegressor()\ncool_model.fit(X, y)\nprint(cool_model.predict(X.head()))\n\n#imports the mean_absolute_error and train_test_split functions and defines the train and test data sets\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n\n#defines cool_model as a decision tree regressor and fits the model to the training set\ncool_model = DecisionTreeRegressor()\ncool_model.fit(train_X, train_y)\n\n#sets val_data_predict equal to the predictions on\nval_data_predict=cool_model.predict(val_X)\nprint(mean_absolute_error(val_y, val_data_predict))\n\n#defines the get_mae function which returns the mean absolute error of the predictions of the data for different numbers of leafs\ndef get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)\n\n#runs a loop for different amounts of leaves and returns the mean absolute error for each\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n\n#reads the test file into the kernel and sets the predictor data equal to test_X\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\ntest_X = test[data_predictors]\n\n#imports the random forest regressor and sets forest_model equal to that and fits it to the training set\nfrom sklearn.ensemble import RandomForestRegressor\nforest_model = RandomForestRegressor()\nforest_model.fit(X, y)\n\n#sets data_predict equal to the prediction on the test model\ndata_predict = forest_model.predict(test_X)\n\n\n#creates csv file with the test id and predicted salePrice\nmy_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': data_predict})\nmy_submission.to_csv('submission.csv', index=False)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "64fde43ae8511da761549c42f24eccb5d1039271",
        "_cell_guid": "06a2e301-f224-40d0-8709-a942b24cd124"
      },
      "cell_type": "markdown",
      "source": "\n**If you have any questions or hit any problems, come to the [Learn Discussion](https://www.kaggle.com/learn-forum) for help. **\n\n**Return to [ML Course Index](https://www.kaggle.com/learn/machine-learning)**"
    },
    {
      "metadata": {
        "_uuid": "704e07440d7d4ef7ad3cf25c0a966c000bb8eeef",
        "_cell_guid": "895df7f1-dab8-4c54-ab7e-9a865146deac"
      },
      "cell_type": "markdown",
      "source": ""
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}